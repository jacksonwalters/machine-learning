{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b454f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pdb\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "#change to working directory\n",
    "os.chdir(r\"C:\\Users\\drusi\\Kaggle\\Prosumer\\predict-energy-behavior-of-prosumers\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccca82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def datestr_to_int(datetime_str, date_format):\n",
    "    try:\n",
    "        # Try parsing with timezone information\n",
    "        dt = datetime.strptime(datetime_str, date_format + '%z')\n",
    "    except ValueError:\n",
    "        # Fallback to parsing without timezone information\n",
    "        dt = datetime.strptime(datetime_str, date_format)\n",
    "    \n",
    "    # Convert to timestamp\n",
    "    timestamp = dt.timestamp()\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "624ca0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_data():\n",
    "    print(\"loading train data...\")\n",
    "    #load the training data, dropping NaN's\n",
    "    train = pd.read_csv(\"train.csv\").dropna()\n",
    "    train['datetime'] = train['datetime'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d %H:%M:%S'))\n",
    "    #shift data_block_id by +1 to line up with electricity_prices and gas_prices\n",
    "    train['data_block_id'] += 1\n",
    "\n",
    "    print(\"Loading client data\")\n",
    "    client = pd.read_csv(\"client.csv\")\n",
    "    client['date'] = client['date'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d'))\n",
    "    client[\"data_block_id\"] += 2\n",
    "    \n",
    "    print(\"loading gas_prices...\")\n",
    "    #load gas_prices\n",
    "    gas_prices = pd.read_csv(\"gas_prices.csv\")\n",
    "    #convert date strings to ints\n",
    "    gas_prices['forecast_date'] = gas_prices['forecast_date'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d'))\n",
    "    gas_prices = gas_prices.drop(columns=['origin_date'])\n",
    "\n",
    "    print(\"loading electricity_prices...\")\n",
    "    #load electricity_prices\n",
    "    electricity_prices = pd.read_csv(\"electricity_prices.csv\")\n",
    "    #convert date strings to ints\n",
    "    electricity_prices['forecast_date'] = electricity_prices['forecast_date'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d %H:%M:%S'))\n",
    "    electricity_prices = electricity_prices.drop(columns=['origin_date'])\n",
    "\n",
    "    print(\"loading forecast_weather...\")\n",
    "    #load forecast_weather\n",
    "    forecast_weather = pd.read_csv(\"forecast_weather.csv\")\n",
    "    #convert strings to ints\n",
    "    forecast_weather['forecast_datetime'] = forecast_weather['forecast_datetime'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d %H:%M:%S'))\n",
    "    forecast_weather = forecast_weather.drop(columns=['origin_datetime'])\n",
    "    forecast_weather = forecast_weather.rename(columns={'forecast_datetime':'forecast_date'})\n",
    "    #shift times to line up with gas/electricity\n",
    "    forecast_weather['forecast_date'] -= 10_800\n",
    "\n",
    "    print(\"loading historical_weather...\")\n",
    "    #load forecast_weather\n",
    "    historical_weather = pd.read_csv(\"historical_weather.csv\")\n",
    "    #convert strings to ints\n",
    "    historical_weather['datetime'] = historical_weather['datetime'].apply(lambda x: datestr_to_int(x,'%Y-%m-%d %H:%M:%S'))\n",
    "    #shift times to line up with gas/electricity\n",
    "\n",
    "    #merge all the data\n",
    "\n",
    "    print(\"Merging train and client\")\n",
    "    # Perform the merge\n",
    "    df = pd.merge(train, client[['product_type', 'is_business', 'county', 'data_block_id', 'eic_count', 'installed_capacity']], \n",
    "               on=['product_type', 'is_business', 'county', 'data_block_id'], \n",
    "               how='left')\n",
    "    print(\"merging train and gas_prices...\")\n",
    "    #merge gas prices and train.csv data\n",
    "    #column names differ, so use left_on and right_on\n",
    "    df = pd.merge(df, gas_prices, left_on=['data_block_id','datetime'], right_on=['data_block_id','forecast_date'], how='left')\n",
    "\n",
    "    print(\"merging electricity_prices...\")\n",
    "    #merge train and gas_prices via left join on data_block_id\n",
    "    #this leaves all rows of train, but matches\n",
    "    df = df.merge(electricity_prices, on=['data_block_id','forecast_date'], how='left')\n",
    "\n",
    "    print(\"merging forecast_weather...\")\n",
    "    #merge forecast_weather on forecast date\n",
    "    df = df.merge(forecast_weather, on=['data_block_id','forecast_date'],how='left')\n",
    "\n",
    "    print(\"merging historical_weather...\")\n",
    "    #merge historical_weather on datetime\n",
    "    df = df.merge(historical_weather, left_on=['data_block_id','forecast_date'], right_on=['data_block_id','datetime'], how='left')\n",
    "\n",
    "    #rename datetime to prediction datetime\n",
    "    df = df.rename(columns={'datetime': 'prediction_datetime'})\n",
    "\n",
    "    #drop NaN rows\n",
    "    df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f4718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "Loading client data\n",
      "loading gas_prices...\n",
      "loading electricity_prices...\n",
      "loading forecast_weather...\n",
      "loading historical_weather...\n",
      "Merging train and client data\n",
      "merging train and gas_prices...\n",
      "merging electricity_prices...\n",
      "merging forecast_weather...\n",
      "merging historical_weather...\n"
     ]
    }
   ],
   "source": [
    "df1 = merged_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9280ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test set: 17.558620695370116\n",
      "Cross-Validation Scores:\n",
      "Fold 1: 29.86328148850852\n",
      "Fold 2: 37.428999947813715\n",
      "Fold 3: 39.26751645321682\n",
      "Fold 4: 36.037484107643685\n",
      "Fold 5: 53.72236923102057\n",
      "Mean Cross-Validation Score: 39.26393024564066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming 'target' is your target column\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Train the model on the entire training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error on test set: {mae}')\n",
    "\n",
    "# Display cross-validation scores\n",
    "print(\"Cross-Validation Scores:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f'Fold {i}: {abs(score)}')\n",
    "\n",
    "# Calculate and display the mean cross-validation score\n",
    "mean_cv_score = abs(cv_scores.mean())\n",
    "print(f'Mean Cross-Validation Score: {mean_cv_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Kaggle\\Prosumer\\models\\xgboost_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the provided data\n",
    "df['prediction_unit_id'] = df.apply(lambda row: hash(tuple(row[['county', 'is_business', 'product_type']])), axis=1)\n",
    "\n",
    "# Load the 'train.csv' file into another DataFrame\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Merge on 'prediction_unit_id' using a left merge\n",
    "merged_df = pd.merge(train_df, df, on='prediction_unit_id', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
